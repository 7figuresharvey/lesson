[ ìš”ì•½ ] 

# ëª©í‘œ : í‹±í†¡ ì˜ìƒì„ í…ìŠ¤íŠ¸ë¡œ ìë™ ë³€í™˜í•˜ëŠ” Python ë„êµ¬ ê°œë°œ
# ëª©í‘œ : Whisper AIë¥¼ í™œìš©í•œ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ êµ¬ì¶•
# ê³ ë¯¼ ì  : ì£¼ë¡œ ë§‰íˆëŠ”ê²Œ 1. ë‚´ë¶€ ë””ë ‰í† ë¦¬ ì˜¤ë¥˜ ( íŒŒì¼ ì°¾ì„ ìˆ˜ ì—†ìŒ ) / 2.api ì—°ë™ì—ì„œ í•­ìƒ ë§‰í™ë‹ˆë‹¤ 

[ ì‚¬ìš© ë„êµ¬ ]

IDE: Cursor AI
ì–¸ì–´: Python 3.13
ìë™í™”: n8n (í–¥í›„ ê³„íš)
ë¼ì´ë¸ŒëŸ¬ë¦¬: OpenAI Whisper


#1. ë‚´ë¶€ ë””ë ‰í† ë¦¬ 

# [ í˜„ì¬ ì½”ë“œ ] 
import whisper
import os
import time
from datetime import datetime

def transcribe_video_to_text(video_path, output_text_path=None, model_size="base"):
    """
    í‹±í†¡ ì˜ìƒì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        video_path (str): ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        output_text_path (str): ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        model_size (str): Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)
    
    Returns:
        str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
    """
    try:
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìë™ ìƒì„±
        if output_text_path is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_text_path = f"{base_name}_{timestamp}_transcript.txt"
        
        print(f"ğŸ¬ ì˜ìƒ íŒŒì¼: {os.path.basename(video_path)}")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_text_path}")
        print(f"ğŸ¤– ëª¨ë¸ í¬ê¸°: {model_size}")
        print("-" * 50)
        
        # Whisper ëª¨ë¸ ë¡œë“œ
        print("â³ Whisper ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
        model = whisper.load_model(model_size)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        print("ğŸ”„ ì˜ìƒ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
        
        # ìŒì„± ì¶”ì¶œ ë° í…ìŠ¤íŠ¸ ë³€í™˜ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        result = model.transcribe(
            video_path, 
            language='ko',
            word_timestamps=True,
            initial_prompt="í‹±í†¡ ìˆí¼ ì˜ìƒì˜ í•œêµ­ì–´ ìŒì„±ì„ ì •í™•íˆ ë³€í™˜í•´ì£¼ì„¸ìš”."
        )
        
        # ê²°ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = result['text']
        
        # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        with open(output_text_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ğŸ¬ í‹±í†¡ ì˜ìƒ í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼\n")
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ“… ë³€í™˜ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ğŸ“ ì›ë³¸ íŒŒì¼: {os.path.basename(video_path)}\n")
            f.write(f"ğŸ¤– ëª¨ë¸ í¬ê¸°: {model_size}\n")
            f.write("-" * 60 + "\n\n")
            
            # ì „ì²´ í…ìŠ¤íŠ¸
            f.write("ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸:\n")
            f.write(full_text + "\n\n")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë³„ í…ìŠ¤íŠ¸
            f.write("â° íƒ€ì„ìŠ¤íƒ¬í”„ë³„ í…ìŠ¤íŠ¸:\n")
            f.write("-" * 40 + "\n")
            for segment in result['segments']:
                start_time_str = format_time(segment['start'])
                end_time_str = format_time(segment['end'])
                f.write(f"[{start_time_str} - {end_time_str}] {segment['text']}\n")
        
        # ì²˜ë¦¬ ì™„ë£Œ ë©”ì‹œì§€
        end_time = time.time()
        processing_time = end_time - start_time
        
        print("âœ… í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_text_path}")
        print(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸: {full_text[:100]}...")
        
        return full_text
        
    except FileNotFoundError:
        error_msg = f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
        print(error_msg)
        return None
        
    except Exception as e:
        error_msg = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(error_msg)
        return None

def format_time(seconds):
    """ì´ˆë¥¼ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    minutes = int(seconds // 60)
    seconds = int(seconds % 60)
    return f"{minutes:02d}:{seconds:02d}"

def batch_process_videos(video_folder, model_size="base"):
    """
    í´ë” ë‚´ ëª¨ë“  ì˜ìƒì„ ì¼ê´„ ì²˜ë¦¬
    
    Args:
        video_folder (str): ì˜ìƒ íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        model_size (str): Whisper ëª¨ë¸ í¬ê¸°
    """
    video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.mp3', '.wav']
    
    if not os.path.exists(video_folder):
        print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_folder}")
        return
    
    video_files = []
    for file in os.listdir(video_folder):
        if any(file.lower().endswith(ext) for ext in video_extensions):
            video_files.append(os.path.join(video_folder, file))
    
    if not video_files:
        print("âŒ ì²˜ë¦¬í•  ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ {len(video_files)}ê°œì˜ ì˜ìƒ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    print("ğŸš€ ì¼ê´„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    for i, video_path in enumerate(video_files, 1):
        print(f"ğŸ“¹ [{i}/{len(video_files)}] ì²˜ë¦¬ ì¤‘: {os.path.basename(video_path)}")
        transcribe_video_to_text(video_path, model_size=model_size)
        print()

if __name__ == "__main__":
    # ì„¤ì •
    VIDEO_PATH = "C:\\Users\\tatw1\\cursor\\snaptik_7499428541549923592.mp4"
    OUTPUT_PATH = "transcription_result.txt"
    MODEL_SIZE = "base"  # tiny, base, small, medium, large
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.isfile(VIDEO_PATH):
        print("âŒ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“ í˜„ì¬ í´ë”ì˜ íŒŒì¼ ëª©ë¡:")
        current_files = [f for f in os.listdir('.') if f.lower().endswith(('.mp4', '.mov', '.avi'))]
        if current_files:
            for file in current_files:
                print(f"  - {file}")
            print("\nìœ„ íŒŒì¼ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ VIDEO_PATHë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
        else:
            print("  ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        result = transcribe_video_to_text(VIDEO_PATH, OUTPUT_PATH, MODEL_SIZE)
        
        if result:
            print("\n" + "="*60)
            print("ğŸ‰ ë³€í™˜ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print("1. í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„")
            print("2. êµ¬ê°„ë³„ ìŠ¤í¬ë¦½íŠ¸ ë¶„í• ")
            print("3. í›„í‚¹ ë©˜íŠ¸ ë¶„ì„")
            print("="*60)
    
    # ì¼ê´„ ì²˜ë¦¬ ì˜ˆì‹œ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
    # batch_process_videos("C:\\Users\\tatw1\\cursor", MODEL_SIZE)

# [ í„°ë¯¸ë„ ì¶œë ¥ ë˜ëŠ” ë‚´ìš© ] 

Traceback (most recent call last):
  File "c:\Users\tatw1\cursor\í‹±í†¡.py", line 1, in <module>
    import whisper
  File "C:\Users\tatw1\AppData\Local\Programs\Python\Python313\Lib\site-packages\whisper\__init__.py", line 13, in <module>
    from .model import ModelDimensions, Whisper
  File "C:\Users\tatw1\AppData\Local\Programs\Python\Python313\Lib\site-packages\whisper\model.py", line 14, in <module>   
    from .transcribe import transcribe as transcribe_function
ImportError: cannot import name 'transcribe' from 'whisper.transcribe' (C:\Users\tatw1\AppData\Local\Programs\Python\Python313\Lib\site-packages\whisper\transcribe.py)
PS C:\Users\tatw1\cursor> 


# ë¬¸ì œ2. ê°•ì œ ë””ë ‰í† ë¦¬ë¡œ ì—°ê²°í–ˆì„ë•ŒëŠ” api ì—°ë™ì´ ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤
